{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Autoencoder in Keras\n",
    "\n",
    "In this tutorial, we will answer some common questions about autoencoders, and we will cover code examples of the following models:\n",
    "\n",
    "    - a deep convolutional autoencoder\n",
    "    - an image denoising model\n",
    "    - a sequence-to-sequence autoencoder\n",
    "    - a variational autoencoder\n",
    "\n",
    "**Note: all code examples have been updated to the Keras 2.0 API on March 14, 2017. You will need Keras version 2.0.0 or higher to run them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print('Your keras version is: ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder\n",
    "\n",
    "Since our inputs are images, it makes sense to use [convolutional neural networks (convnets)](https://www.safaribooksonline.com/library/view/deep-learning/9781491924570/ch04.html) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders -- they simply perform much better.\n",
    "\n",
    "Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train it, we will use the original MNIST digits with shape (samples, 3, 28, 28), and we will just normalize pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this model for 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converges to a loss of 0.099, significantly better than our previous models (this is in large part due to the higher entropic capacity of the encoded representation, 128 dimensions vs. 32 previously). Let's take a look at the reconstructed digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utility function for showing images\n",
    "def show_imgs(x_test, decoded_imgs=None, n=10):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(28,28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if decoded_imgs is not None:\n",
    "            ax = plt.subplot(2, n, i+ 1 +n)\n",
    "            plt.imshow(decoded_imgs[i].reshape(28,28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "print(\"input (upper row)\\ndecoded (bottom row)\")\n",
    "show_imgs(x_test, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR TURN HERE\n",
    "\n",
    "Q: Comparing above results to the results in part0, is it much improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (double click to fill in your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Denoising Autoencoder\n",
    "\n",
    "As discussed in part0, image (data) denoising is one of the most important functions of autoencoders. Let's put our convolutional autoencoder to work on an image denoising problem. It's simple: we will train the autoencoder to map noisy digits images to clean digits images.\n",
    "\n",
    "Here's how we will generate synthetic noisy digits: we just apply a gaussian noise matrix and clip the images between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the noisy digits look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noisy digits look like below: \")\n",
    "show_imgs(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you squint you can still recognize them, but barely. Can our autoencoder learn to recover the original digits? Let's find out.\n",
    "\n",
    "Compared to the previous convolutional autoencoder, in order to improve the quality of the reconstructed, we'll use a slightly different model with more filters per layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code block will take 30+ mins to run.\n",
    "\n",
    "**NOTE: I would suggest you skip next step and the step below it *in class*, and resume on it on your own time so you can follow along.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "print(\"noisy (upper row)\\ndecoded (bottom row)\")\n",
    "show_imgs(x_test_noisy, decoded_imgs)\n",
    "print(\"original\")\n",
    "show_imgs(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A Sequence-to-Sequence Autoencoder\n",
    "\n",
    "Above autoencoders are cute and interesting - but can we get more practical than compressing and denoising images?\n",
    "\n",
    "Have you ever wondered how agents like **Google Translate** works? Autoencoder can do something like that - now it sounds more interesting, doesn't it?\n",
    "\n",
    "As discussed in the lecture, Recurrent Neural Networks (RNN) can capture sequential information - hence, the encoder-decoder model provides a pattern for using RNN layers (or in particular, LSTM) to address challenging sequence-to-sequence prediction problems, such as **machine translation**.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "    - How to correctly define a sophisticated encoder-decoder model in Keras for sequence-to-sequence prediction.\n",
    "    - How to define a contrived yet scalable sequence-to-sequence prediction problem that you can use to evaluate the encoder-decoder LSTM model.\n",
    "    - How to apply the encoder-decoder LSTM model in Keras to address the scalable integer sequence-to-sequence prediction problem.\n",
    "\n",
    "We already know that we can embed words as (elements in) vectors, and it is difficult to find a non English language that we are all proficient in - so let's play with some embedded words. In this case, we are using numbers/vectors to represent words, so we do not have to play with some foreign language.\n",
    "\n",
    "*As an example, vector X = [1, 267, 5, 38] represents sentence \"the summer is here\".*\n",
    "\n",
    "Let’s get started!\n",
    "### Build an RNN-based Encoder-Decoder Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder-decoder model is a way of organizing recurrent neural networks for sequence-to-sequence prediction problems.\n",
    "\n",
    "It was originally developed for **machine translation** problems, although it has proven successful at related **sequence-to-sequence prediction** problems such as **text summarization** and **question answering**.\n",
    "\n",
    "**PROJECT HINT**: more interests have been spent on using sequence-to-sequence prediction on time-series data.\n",
    "\n",
    "The approach involves two **recurrent neural networks**, one to encode the source sequence, called the **encoder**, and a second to decode the encoded source sequence into the target sequence, called the **decoder**. But you already knew them, don't you?\n",
    "\n",
    "The Keras deep learning Python library provides an example of how to implement the encoder-decoder model for machine translation ([lstm_seq2seq.py](https://github.com/fchollet/keras/blob/master/examples/lstm_seq2seq.py)) described by the libraries creator in the post: [“A ten-minute introduction to sequence-to-sequence learning in Keras.”](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "\n",
    "Using the code in that example as a starting point, here we will develop a generic function to define an encoder-decoder recurrent neural network. \n",
    "\n",
    "The function needs to take 3 arguments, as follows:\n",
    "\n",
    "- n_input: The cardinality of the input sequence, e.g. number of features, words, or characters for each time step.\n",
    "- n_output: The cardinality of the output sequence, e.g. number of features, words, or characters for each time step.\n",
    "- n_units: The number of cells/**neurons**to create in the encoder and decoder models, e.g. 128 or 256.\n",
    "\n",
    "The function then creates and returns 3 models, as follows:\n",
    "\n",
    "- train: Model that can be trained given source, target, and shifted target sequences.\n",
    "- inference_encoder: Encoder model used when making a prediction for a new source sequence.\n",
    "- inference_decoder Decoder model use when making a prediction for a new source sequence.\n",
    "\n",
    "Below is this function named **define_models()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_models(n_input, n_output, n_units):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained given source and target sequences where the model takes both the **source** and a *shifted* version of the **target** sequence as input and predicts the **whole target** sequence.\n",
    "\n",
    "For example, one source sequence may be [1,2,3] and the target sequence [4,5,6]. The inputs and outputs to the model during training would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input1: ['1', '2', '3'] # Source\n",
    "Input2: ['_', '4', '5'] # Shifted version of target\n",
    "Output: ['4', '5', '6'] # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is intended to be called recursively when generating target sequences for new source sequences.\n",
    "\n",
    "The source sequence is encoded and the target sequence is generated one element at a time, using a “start of sequence” character such as ‘_’ to start the process. Therefore, in the above case, the following input-output pairs would occur during training:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t, \tInput1,\t\t\t\tInput2,\t\tOutput\n",
    "1,  ['1', '2', '3'],\t'_',\t\t'4'     # Iteration 1\n",
    "2,  ['1', '2', '3'],\t'4',\t\t'5'     # Iteration 2\n",
    "3,  ['1', '2', '3'],\t'5',\t\t'6'     # Iteration 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see how the recursive use of the model can be used to build up output sequences.\n",
    "\n",
    "During *prediction*, the **inference_encoder model** is used to encode the input sequence *once* which returns states that are used to **initialize the inference_decoder model**. From that point, the **inference_decoder model** is used to **generate predictions step by step**.\n",
    "\n",
    "The function below named **predict_sequence()** can be used after the model is trained to generate a target sequence given a source sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes 5 arguments as follows:\n",
    "\n",
    "- infenc: Encoder model used when making a prediction for a new source sequence.\n",
    "- infdec: Decoder model use when making a prediction for a new source sequence.\n",
    "- source: Encoded source sequence.\n",
    "- n_steps: Number of time steps in the target sequence.\n",
    "- cardinality: The cardinality of the output sequence, e.g. the number of features, words, or characters for each time step.\n",
    "\n",
    "The function then returns a list containing the target sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalable Sequence-to-Sequence Problem\n",
    "\n",
    "In this section, we define a contrived and scalable sequence-to-sequence prediction problem.\n",
    "\n",
    "The source sequence is a series of randomly generated integer values, such as [20, 36, 40, 10, 34, 28], and the target sequence is a reversed pre-defined subset of the input sequence, such as the first 3 elements in reverse order [40, 36, 20].\n",
    "\n",
    "**EXPLANATION**: if the original sequence is a word embedding in language X, we are doing a weird translation where foreign language Y actually takes the first three words in X and reverse them in order.\n",
    "\n",
    "The length of the source sequence is configurable; so is the cardinality of the input and output sequence and the length of the target sequence.\n",
    "\n",
    "We will use source sequences of 6 elements, a cardinality of 50, and target sequences of 3 elements.\n",
    "\n",
    "**EXPLANATION**: every sentence in language X has 6 words, and every sentence in language Y has 3 words. This is a common practice in text analytics - if the sentence in X has more than 6 words, the 7th word and on will be pruned; if the sentence has less than 6 words, it will be padded to 6.\n",
    "\n",
    "Below are some more examples to make this concrete."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Source (X),\t\t\t\t\tTarget (Y)\n",
    "[13, 28, 18, 7, 9, 5]\t\t[18, 28, 13]\n",
    "[29, 44, 38, 15, 26, 22]\t[38, 44, 29]\n",
    "[27, 40, 31, 29, 32, 1]\t\t[31, 40, 27]\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start off by defining a function to generate a sequence of random integers.\n",
    "\n",
    "We will use the value of **0** as the padding or start of sequence character, therefore it is reserved and we cannot use it in our source sequences. To achieve this, we will add 1 to our configured cardinality to ensure the one-hot encoding is large enough (e.g. a value of 1 maps to a ‘1’ value in index 1).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 50 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the randint() python function to generate random integers in a range between 1 and 1-minus the size of the problem’s cardinality. \n",
    "\n",
    "The generate_sequence() below generates a sequence of random integers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate a sequence of random integers\n",
    "def generate_sequence(length, n_unique):\n",
    "    return [randint(1, n_unique-1) for _ in range(length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create the corresponding output sequence given the source sequence.\n",
    "\n",
    "To keep thing simple, we will select the first n elements of the source sequence as the target sequence and reverse them."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# define target sequence\n",
    "target = source[:n_out]\n",
    "target.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a version of the output sequence shifted forward by one time step that we can use as the mock target generated so far, including the start of sequence value in the first time step. We can create this from the target sequence directly.\n",
    "\n",
    "**EXPLANATION**: This is the step to create the shifted version of the target."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create padded input target sequence\n",
    "target_in = [0] + target[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the sequences have been defined, we can one-hot encode them, i.e. transform them into sequences of binary vectors. We can use the Keras built in to_categorical() function to achieve this.\n",
    "\n",
    "We can put all of this into a function named get_dataset() that will generate a specific number of sequences that we can use to train a model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# prepare data for the LSTM\n",
    "def get_dataset(n_in, n_out, cardinality, n_samples):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for _ in range(n_samples):\n",
    "        # generate source sequence\n",
    "        source = generate_sequence(n_in, cardinality)\n",
    "        # define target sequence\n",
    "        target = source[:n_out]\n",
    "        target.reverse()\n",
    "        # create padded input target sequence\n",
    "        target_in = [0] + target[:-1]\n",
    "        # One-hot encoding - this is NOT our autoencoder here\n",
    "        src_encoded = to_categorical([source], num_classes=cardinality)\n",
    "        tar_encoded = to_categorical([target], num_classes=cardinality)\n",
    "        tar2_encoded = to_categorical([target_in], num_classes=cardinality)\n",
    "        # store\n",
    "        X1.append(src_encoded)\n",
    "        X2.append(tar2_encoded)\n",
    "        y.append(tar_encoded)\n",
    "    return array(X1), array(X2), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to be able to decode a one-hot encoded sequence to make it readable again.\n",
    "\n",
    "This is needed for both printing the generated target sequences but also for easily comparing whether the full predicted target sequence matches the expected target sequence. The one_hot_decode() function will decode an encoded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first prints the shape of the generated dataset, ensuring the 3D shape required to train the model matches our expectations.\n",
    "\n",
    "The generated sequence is then decoded and printed to screen demonstrating both that the preparation of source and target sequences matches our intention and that the decode operation is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# generate a sequence of random integers\n",
    "def generate_sequence(length, n_unique):\n",
    "    return [randint(1, n_unique-1) for _ in range(length)]\n",
    "\n",
    "# prepare data for the LSTM\n",
    "def get_dataset(n_in, n_out, cardinality, n_samples):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for _ in range(n_samples):\n",
    "        # generate source sequence\n",
    "        source = generate_sequence(n_in, cardinality)\n",
    "        # define target sequence\n",
    "        target = source[:n_out]\n",
    "        target.reverse()\n",
    "        # create padded input target sequence\n",
    "        target_in = [0] + target[:-1]\n",
    "        # encode\n",
    "        src_encoded = to_categorical([source], num_classes=cardinality)\n",
    "        tar_encoded = to_categorical([target], num_classes=cardinality)\n",
    "        tar2_encoded = to_categorical([target_in], num_classes=cardinality)\n",
    "        # store\n",
    "        X1.append(src_encoded)\n",
    "        X2.append(tar2_encoded)\n",
    "        y.append(tar_encoded)\n",
    "    return array(X1), array(X2), array(y)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# configure problem\n",
    "n_features = 50 + 1\n",
    "n_steps_in = 6\n",
    "n_steps_out = 3\n",
    "# generate a single source and target sequence\n",
    "X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "print(X1.shape, X2.shape, y.shape)\n",
    "print('X1=%s, X2=%s, y=%s' % (one_hot_decode(X1[0]), one_hot_decode(X2[0]), one_hot_decode(y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to develop a model for this sequence-to-sequence prediction problem.\n",
    "\n",
    "###Encoder-Decoder LSTM for Sequence Prediction\n",
    "\n",
    "In this section, we will apply the encoder-decoder LSTM model developed in the first section to the sequence-to-sequence prediction problem developed in the second section.\n",
    "\n",
    "The first step is to configure the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "#### fill in here\n",
    "\n",
    "# We want the cardinality as 50 - so we are generating numbers between 1 and 50\n",
    "#### NOTE that in text analytics this is the size of our dictionary \n",
    "n_features = 50 + 1 \n",
    "\n",
    "# We want 8 elements in X\n",
    "n_steps_in = 6\n",
    "\n",
    "# We want 4 elements in X\n",
    "n_steps_out = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must define the models and compile the training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "train, infenc, infdec = define_models(n_features, n_features, 128)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate a training dataset of 100,000 examples and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training dataset\n",
    "X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\n",
    "print(X1.shape,X2.shape,y.shape)\n",
    "# train model\n",
    "train.fit([X1, X2], y, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN HERE\n",
    "\n",
    "Please report the shapes of the **Source**, **Shifted Target**, and the **Target** datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click here to enter your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we can evaluate it. We will do this by making predictions for 100 source sequences and counting the number of target sequences that were predicted correctly. We will use the numpy array_equal() function on the decoded sequences to check for equality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model is fit. You should see a progress bar and the run should take less than one minute on a modern multi-core CPU.\n",
    "\n",
    "### YOUR TURN HERE\n",
    "Please report and try to interpret the loss and accuracy from above model below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click here to enter your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model is evaluated and the accuracy printed. We can see that the model achieves 100% accuracy on new randomly generated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate LSTM\n",
    "total, correct = 100, 0\n",
    "for _ in range(total):\n",
    "    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "    if array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\n",
    "        correct += 1\n",
    "print('Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will generate some predictions and print the decoded source, target, and predicted target sequences to get an idea of whether the model is working as expected.\n",
    "\n",
    "As you can see, 10 new examples are generated and target sequences are predicted. Again, we can see that the model correctly predicts the output sequence in each case and the expected value matches the reversed first 3 elements of the source sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check some examples\n",
    "for _ in range(10):\n",
    "    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "    print('X=%s y=%s, yhat=%s' % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN HERE\n",
    "\n",
    "Use the code provided above, randomly generate 200,000 source sequences (X), and 200 target sequences (Y) accordingly.\n",
    "\n",
    "Each sequence in X should have 8 elements, each sequence in Y is the reverse of the latter 4 elements of X.\n",
    "\n",
    "Train a new model to use new X to predict Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variantional Autoencoders (VAE)\n",
    "\n",
    "VAE are very important autoencoders - we often use them to generate simulation data. Due to the time limit I cannot do this in class, but you can follow [this detailed tutorial](https://www.datacamp.com/community/tutorials/autoencoder-keras-tutorial) on building VAEs with image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Reading Materials\n",
    "\n",
    "1. [How to Define an Encoder-Decoder Sequence-to-Sequence Model for Neural Machine Translation in Keras](https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/)\n",
    "\n",
    "2. [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
